{"cells":[{"cell_type":"code","execution_count":40,"id":"93e7dae3-c192-4267-a0ed-18d1ac56c861","metadata":{"collapsed":true,"executionCancelledAt":null,"executionTime":5968,"jupyter":{"outputs_hidden":true,"source_hidden":false},"lastExecutedAt":1721825502013,"lastExecutedByKernel":"36600d2c-7e2e-440c-b64a-525124e4d7df","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"!pip install torchmetrics\n!pip install torchvision","outputsMetadata":{"0":{"height":544,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: torchmetrics in /home/repl/.local/lib/python3.8/site-packages (1.4.0.post0)\n","Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.23.2)\n","Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (23.2)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (1.13.0)\n","Requirement already satisfied: lightning-utilities>=0.8.0 in /home/repl/.local/lib/python3.8/site-packages (from torchmetrics) (0.11.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (4.9.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (65.6.3)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.7.99)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.10.3.66)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch>=1.10.0->torchmetrics) (11.7.99)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.10.0->torchmetrics) (0.38.4)\n","Defaulting to user installation because normal site-packages is not writeable\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torchvision) (4.9.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.23.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.31.0)\n","Requirement already satisfied: torch==1.13.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.13.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (9.2.0)\n","Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.0->torchvision) (11.7.99)\n","Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.0->torchvision) (8.5.0.96)\n","Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.0->torchvision) (11.10.3.66)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch==1.13.0->torchvision) (11.7.99)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchvision) (65.6.3)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchvision) (0.38.4)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision) (2.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->torchvision) (1.25.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision) (2019.11.28)\n"]}],"source":["!pip install torchmetrics\n","!pip install torchvision"]},{"cell_type":"code","execution_count":41,"id":"ea8065b7-84fc-4376-afef-6db731dec4b3","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1721825502069,"lastExecutedByKernel":"36600d2c-7e2e-440c-b64a-525124e4d7df","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics import Accuracy, Precision, Recall"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchmetrics import Accuracy, Precision, Recall"]},{"cell_type":"code","execution_count":42,"id":"662e1bf1-943f-4243-9fd4-02ce11609e8d","metadata":{"collapsed":true,"executionCancelledAt":null,"executionTime":137,"jupyter":{"outputs_hidden":true,"source_hidden":false},"lastExecutedAt":1721825502207,"lastExecutedByKernel":"36600d2c-7e2e-440c-b64a-525124e4d7df","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Load datasets\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\n\ntrain_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\ntest_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())","outputsMetadata":{"0":{"height":80,"type":"stream"},"1":{"height":38,"type":"stream"},"2":{"height":122,"type":"stream"},"3":{"height":38,"type":"stream"},"4":{"height":122,"type":"stream"},"5":{"height":38,"type":"stream"},"6":{"height":122,"type":"stream"},"7":{"height":38,"type":"stream"},"8":{"height":59,"type":"stream"}}},"outputs":[],"source":["# Load datasets\n","from torchvision import datasets\n","import torchvision.transforms as transforms\n","\n","train_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n","test_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"]},{"cell_type":"code","execution_count":43,"id":"bb5ad316-37ea-4125-9093-7cbeab80862b","metadata":{"executionCancelledAt":null,"executionTime":54,"lastExecutedAt":1721825502262,"lastExecutedByKernel":"36600d2c-7e2e-440c-b64a-525124e4d7df","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Initializing important variables\nnum_classes = len(train_data.classes)\nnum_input_channels = 1\nnum_output_channels = 16\nimage_size = train_data[0][0].shape[1]\n\n# Training data loader\ndataloader_train = DataLoader(\n    train_data,\n    batch_size = 10,\n    shuffle = True,\n)\n\n# Testing data loader\ndataloader_test = DataLoader(\n    test_data,\n    batch_size = 10,\n    shuffle = False,\n)"},"outputs":[],"source":["# Initializing important variables\n","num_classes = len(train_data.classes)\n","num_input_channels = 1\n","num_output_channels = 16\n","image_size = train_data[0][0].shape[1]\n","\n","# Training data loader\n","dataloader_train = DataLoader(\n","    train_data,\n","    batch_size = 10,\n","    shuffle = True,\n",")\n","\n","# Testing data loader\n","dataloader_test = DataLoader(\n","    test_data,\n","    batch_size = 10,\n","    shuffle = False,\n",")"]},{"cell_type":"code","execution_count":44,"id":"fb17ad71-15a0-41a1-910f-0e5e4e316bb9","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1721825502313,"lastExecutedByKernel":"36600d2c-7e2e-440c-b64a-525124e4d7df","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Defining the neural network\nclass Net(nn.Module):\n    def __init__(self, num_classes):\n        super(Net, self).__init__()\n        # Define feature extractor\n        self.feature_extractor = nn.Sequential(\n            nn.Conv2d(num_input_channels, num_output_channels, kernel_size=3, stride=1, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.Flatten(),\n        )\n        # Define classifier\n        self.classifier = nn.Linear(num_output_channels * (image_size//2)**2, num_classes)\n    \n    def forward(self, x):  \n        # Pass input through feature extractor and classifier\n        x = self.feature_extractor(x)\n        x = self.classifier(x)\n        return x"},"outputs":[],"source":["# Defining the neural network\n","class Net(nn.Module):\n","    def __init__(self, num_classes):\n","        super(Net, self).__init__()\n","        # Define feature extractor\n","        self.feature_extractor = nn.Sequential(\n","            nn.Conv2d(num_input_channels, num_output_channels, kernel_size=3, stride=1, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=2, stride=2),\n","            nn.Flatten(),\n","        )\n","        # Define classifier\n","        self.classifier = nn.Linear(num_output_channels * (image_size//2)**2, num_classes)\n","    \n","    def forward(self, x):  \n","        # Pass input through feature extractor and classifier\n","        x = self.feature_extractor(x)\n","        x = self.classifier(x)\n","        return x"]},{"cell_type":"code","execution_count":45,"id":"f5e2b43b-c8f2-407e-8a28-2ccb7374cd42","metadata":{"executionCancelledAt":null,"executionTime":95147,"lastExecutedAt":1721825597461,"lastExecutedByKernel":"36600d2c-7e2e-440c-b64a-525124e4d7df","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define the model\nnet = Net(num_classes=num_classes)\n# Define the loss function\ncriterion = nn.CrossEntropyLoss()\n# Define the optimizer\noptimizer = optim.Adam(net.parameters(), lr=0.001)\n\nfor epoch in range(2):\n    running_loss = 0.0\n    # Iterate over training batches\n    for images, labels in dataloader_train:\n        optimizer.zero_grad()\n        outputs = net(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n    \n    epoch_loss = running_loss / len(dataloader_train)\n    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")","outputsMetadata":{"0":{"height":59,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1, Loss: 0.3992\n","Epoch 2, Loss: 0.2935\n"]}],"source":["# Define the model\n","net = Net(num_classes=num_classes)\n","# Define the loss function\n","criterion = nn.CrossEntropyLoss()\n","# Define the optimizer\n","optimizer = optim.Adam(net.parameters(), lr=0.001)\n","\n","for epoch in range(2):\n","    running_loss = 0.0\n","    # Iterate over training batches\n","    for images, labels in dataloader_train:\n","        optimizer.zero_grad()\n","        outputs = net(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss += loss.item()\n","    \n","    epoch_loss = running_loss / len(dataloader_train)\n","    print(f\"Epoch {epoch+1}, Loss: {epoch_loss:.4f}\")"]},{"cell_type":"code","execution_count":46,"id":"a69bc167-1ad5-4e52-abbe-48c02a8afecf","metadata":{"executionCancelledAt":null,"executionTime":9855,"lastExecutedAt":1721825607317,"lastExecutedByKernel":"36600d2c-7e2e-440c-b64a-525124e4d7df","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define the metrics\naccuracy_metric = Accuracy(task='multiclass', num_classes=num_classes)\nprecision_metric = Precision(task='multiclass', num_classes=num_classes, average=None)\nrecall_metric = Recall(task='multiclass', num_classes=num_classes, average=None)\n\n# Run model on test set\nnet.eval()\npredictions = []\nfor i, (features, labels) in enumerate(dataloader_test):\n    output = net.forward(features.reshape(-1, 1, image_size, image_size))\n    cat = torch.argmax(output, dim=-1)\n    predictions.extend(cat.tolist())\n    accuracy_metric(cat, labels)\n    precision_metric(cat, labels)\n    recall_metric(cat, labels)\n\n# Compute the metrics\naccuracy = accuracy_metric.compute().item()\nprecision = precision_metric.compute().tolist()\nrecall = recall_metric.compute().tolist()\nprint('Accuracy:', accuracy)\nprint('Precision (per class):')\nfor i, prec in enumerate(precision, start=1):\n    print(f'    Class {i}: {prec:.16f}')\n\nprint('Recall (per class):')\nfor i, rec in enumerate(recall, start=1):\n    print(f'    Class {i}: {rec:.16f}')","outputsMetadata":{"0":{"height":500,"type":"stream"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.8902000188827515\n","Precision (per class):\n","    Class 1: 0.8339843750000000\n","    Class 2: 0.9888211488723755\n","    Class 3: 0.8101145029067993\n","    Class 4: 0.9043210148811340\n","    Class 5: 0.8162055611610413\n","    Class 6: 0.9563530683517456\n","    Class 7: 0.7027027010917664\n","    Class 8: 0.9732906222343445\n","    Class 9: 0.9838056564331055\n","    Class 10: 0.9357622265815735\n","Recall (per class):\n","    Class 1: 0.8539999723434448\n","    Class 2: 0.9729999899864197\n","    Class 3: 0.8489999771118164\n","    Class 4: 0.8790000081062317\n","    Class 5: 0.8259999752044678\n","    Class 6: 0.9860000014305115\n","    Class 7: 0.6759999990463257\n","    Class 8: 0.9110000133514404\n","    Class 9: 0.9720000028610229\n","    Class 10: 0.9760000109672546\n"]}],"source":["# Define the metrics\n","accuracy_metric = Accuracy(task='multiclass', num_classes=num_classes)\n","precision_metric = Precision(task='multiclass', num_classes=num_classes, average=None)\n","recall_metric = Recall(task='multiclass', num_classes=num_classes, average=None)\n","\n","# Run model on test set\n","net.eval()\n","predictions = []\n","for i, (features, labels) in enumerate(dataloader_test):\n","    output = net.forward(features.reshape(-1, 1, image_size, image_size))\n","    cat = torch.argmax(output, dim=-1)\n","    predictions.extend(cat.tolist())\n","    accuracy_metric(cat, labels)\n","    precision_metric(cat, labels)\n","    recall_metric(cat, labels)\n","\n","# Compute the metrics\n","accuracy = accuracy_metric.compute().item()\n","precision = precision_metric.compute().tolist()\n","recall = recall_metric.compute().tolist()\n","print('Accuracy:', accuracy)\n","print('Precision (per class):')\n","for i, prec in enumerate(precision, start=1):\n","    print(f'    Class {i}: {prec:.16f}')\n","\n","print('Recall (per class):')\n","for i, rec in enumerate(recall, start=1):\n","    print(f'    Class {i}: {rec:.16f}')"]}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"editor":"DataLab","kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}
